name: CI

on:
  push:
    branches: [main]
    paths-ignore:
      - "docs/**"
      - "README.md"
      - "SPEC.md"
      - "testing_strategy.md"
      - "CHANGELOG.md"
      - "VERSIONING.md"
  pull_request:
    branches: [main]
    paths-ignore:
      - "docs/**"
      - "README.md"
      - "SPEC.md"
      - "testing_strategy.md"
      - "CHANGELOG.md"
      - "VERSIONING.md"
  workflow_dispatch:

# Cancel in-progress runs when a new commit is pushed to the same branch/PR
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  CARGO_TERM_COLOR: always

jobs:
  # Build job - compiles once and shares artifacts
  build:
    name: Build
    runs-on: ubuntu-latest
    timeout-minutes: 25
    permissions:
      contents: read
      actions: write  # Required for sccache to write to GitHub Actions cache
    steps:
      - uses: actions/checkout@v4

      - name: Install Protobuf Compiler
        uses: arduino/setup-protoc@v3
        with:
          version: "25.x"

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Setup sccache
        uses: mozilla-actions/sccache-action@v0.0.9

      - name: Configure sccache
        run: |
          echo "SCCACHE_GHA_ENABLED=true" >> $GITHUB_ENV
          echo "RUSTC_WRAPPER=sccache" >> $GITHUB_ENV

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
          key: ${{ runner.os }}-cargo-registry-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-registry-

      - name: Build all targets
        run: cargo build --all-targets

      - name: Run Clippy
        run: cargo clippy --all-targets -- -D warnings

      - name: Save build artifacts
        uses: actions/cache/save@v4
        with:
          path: target
          key: ${{ runner.os }}-build-${{ github.sha }}

  # Format check - runs in parallel (no build needed)
  lint:
    name: Format Check
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt

      - name: Check formatting
        run: cargo fmt --check

  # Unit and integration tests - runs after build
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4

      - name: Install Protobuf Compiler
        uses: arduino/setup-protoc@v3
        with:
          version: "25.x"

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Restore cargo registry
        uses: actions/cache/restore@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
          key: ${{ runner.os }}-cargo-registry-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-registry-

      - name: Restore build artifacts
        uses: actions/cache/restore@v4
        with:
          path: target
          key: ${{ runner.os }}-build-${{ github.sha }}

      - name: Run all tests
        run: cargo test 2>&1 | tee test-output.log

      - name: Verify benchmarks compile (main only)
        if: github.ref == 'refs/heads/main'
        run: cargo bench --no-run

      - name: Upload test logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: test-logs
          path: test-output.log
          retention-days: 7

  # Documentation coherence check - runs in parallel (no build needed)
  docs-check:
    name: Documentation Coherence
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4

      - name: Check documentation coherence
        run: ./scripts/check-docs-coherence.sh

  # Security audit - runs in parallel (no build needed)
  security:
    name: Dependency Audit
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4

      - name: Install cargo-deny
        uses: baptiste0928/cargo-install@v3
        with:
          crate: cargo-deny
          version: "0.18"

      - name: Check dependencies
        run: cargo deny check

  # Code quality checks - runs in parallel (no build needed)
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4

      - name: Check for .unwrap() in library code
        run: |
          echo "Checking for NEW .unwrap() violations (excluding known legacy code)..."

          # Known legacy violations that pre-date this check (to be fixed in separate PRs)
          # These are grandfathered in to avoid blocking unrelated PRs
          KNOWN_LEGACY="
          src/storage/parquet.rs:186
          src/storage/parquet.rs:187
          src/storage/parquet.rs:188
          src/storage/parquet.rs:189
          src/storage/parquet.rs:221
          src/storage/parquet.rs:222
          src/storage/parquet.rs:223
          src/storage/parquet.rs:224
          src/storage/parquet.rs:267
          src/storage/parquet.rs:268
          src/storage/parquet.rs:269
          src/storage/parquet.rs:270
          src/storage/iceberg.rs:430
          src/storage/iceberg.rs:440
          "

          # Create a script to check for unwrap() outside of test modules
          cat > /tmp/check_unwrap.py << 'SCRIPT'
          import sys
          import re
          import os

          KNOWN_LEGACY = set(os.environ.get('KNOWN_LEGACY', '').split())

          def check_file(filepath):
              with open(filepath) as f:
                  content = f.read()
                  lines = content.split('\n')

              in_test_section = False
              brace_depth = 0
              test_start_depth = 0
              violations = []

              for i, line in enumerate(lines, 1):
                  # Track entering test modules
                  if re.search(r'#\[cfg\(test\)\]|mod tests\s*\{', line):
                      in_test_section = True
                      test_start_depth = brace_depth

                  # Track brace depth
                  brace_depth += line.count('{') - line.count('}')

                  # Exit test section when braces balance
                  if in_test_section and brace_depth <= test_start_depth:
                      in_test_section = False

                  # Skip test code, test functions, constants, and allowed patterns
                  if in_test_section:
                      continue
                  if '#[test]' in line or 'fn test_' in line:
                      continue
                  if 'const ' in line and '.unwrap()' in line:
                      continue
                  if 'unwrap_or' in line:
                      continue
                  if '// SAFETY:' in line or '// OK:' in line:
                      continue

                  # Check for unwrap
                  if '.unwrap()' in line:
                      location = f"{filepath}:{i}"
                      if location not in KNOWN_LEGACY:
                          violations.append(f"{location}: {line.strip()}")

              return violations

          import glob
          all_violations = []
          for f in glob.glob('src/**/*.rs', recursive=True):
              all_violations.extend(check_file(f))

          if all_violations:
              for v in all_violations:
                  print(v)
              sys.exit(1)
          sys.exit(0)
          SCRIPT

          export KNOWN_LEGACY
          if python3 /tmp/check_unwrap.py; then
            echo "✅ No new .unwrap() violations found"
          else
            echo ""
            echo "❌ Found NEW .unwrap() in library code!"
            echo ""
            echo "CLAUDE.md requires: No unwrap() or expect() in library code"
            echo "Use '?' operator or explicit error handling instead."
            echo ""
            echo "If this is intentional, add a comment:"
            echo "  // SAFETY: This unwrap is safe because..."
            exit 1
          fi

      - name: Check for code duplication patterns
        run: |
          echo "Checking for common code duplication..."

          # Check for duplicate constant definitions
          EPOCH_DEFS=$(grep -rn "from_ymd_opt(1970, 1, 1)" src/ --include="*.rs" | wc -l)
          if [ "$EPOCH_DEFS" -gt 1 ]; then
            echo "❌ Found multiple Unix epoch date definitions:"
            grep -rn "from_ymd_opt(1970, 1, 1)" src/ --include="*.rs"
            echo ""
            echo "Use the existing UNIX_EPOCH_DATE constant from parquet.rs"
            exit 1
          fi

          echo "✅ No obvious code duplication found"

      - name: Check PR description format (PRs only)
        if: github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "Checking PR description..."

          PR_BODY=$(gh pr view ${{ github.event.pull_request.number }} --json body -q .body)

          # Check for issue reference
          if ! echo "$PR_BODY" | grep -qiE "(closes|fixes|resolves)\s*#[0-9]+"; then
            echo "⚠️  Warning: PR description should reference an issue"
            echo "   Use: 'Closes #N' or 'Fixes #N' to auto-close issues"
          fi

          echo "✅ PR description check complete"

  # Benchmark regression check - opt-in via label or keyword
  # To trigger: add 'performance' label OR include '[benchmark]' in PR title/body
  bench-regression:
    name: Benchmark Regression Check
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: |
      github.event_name == 'pull_request' && (
        contains(github.event.pull_request.labels.*.name, 'performance') ||
        contains(github.event.pull_request.title, '[benchmark]') ||
        contains(github.event.pull_request.body, '[benchmark]')
      )
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for comparison

      - name: Install Protobuf Compiler
        uses: arduino/setup-protoc@v3
        with:
          version: "25.x"

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Setup sccache
        uses: mozilla-actions/sccache-action@v0.0.9

      - name: Configure sccache
        run: |
          echo "SCCACHE_GHA_ENABLED=true" >> $GITHUB_ENV
          echo "RUSTC_WRAPPER=sccache" >> $GITHUB_ENV

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-

      - name: Install critcmp (cached)
        uses: baptiste0928/cargo-install@v3
        with:
          crate: critcmp
          version: "0.1"

      - name: Run benchmarks on PR branch
        run: |
          cargo bench --bench write_throughput -- --save-baseline pr

      - name: Checkout main branch
        run: |
          git fetch origin main
          git checkout origin/main

      - name: Run benchmarks on main branch
        run: |
          cargo bench --bench write_throughput -- --save-baseline main

      - name: Compare benchmarks
        run: |
          critcmp main pr > comparison.txt || true
          cat comparison.txt

          # Check for regressions > 10% (matches 10.0% through 999.9%)
          if grep -E "\+(1[0-9]|[2-9][0-9]|[0-9]{3,})\.[0-9]+%" comparison.txt; then
            echo "❌ Significant performance regression detected (>10%)"
            echo "See comparison above. If this is expected, provide justification in PR."
            exit 1
          fi

          # Warn about regressions 5-10%
          if grep -E "\+[5-9]\.[0-9]+%" comparison.txt; then
            echo "⚠️  Performance regression 5-10% detected"
            echo "This requires justification and maintainer approval."
          fi

          echo "✅ No significant performance regressions detected"

      - name: Upload benchmark comparison
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-comparison
          path: comparison.txt
          retention-days: 30


  # Docker build - runs only on main
  docker:
    name: Docker Build
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [lint, test, docs-check, security, code-quality]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}
          tags: |
            type=sha
            type=raw,value=latest

      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          platforms: linux/amd64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Integration test for PRs - builds Docker image locally
  integration-pr:
    name: Integration Test (PR)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [lint, test, docs-check, security, code-quality]
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image locally
        uses: docker/build-push-action@v5
        with:
          context: .
          load: true
          tags: zombi:pr-${{ github.event.pull_request.number }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Start MinIO
        run: |
          docker run -d --name minio \
            -p 9000:9000 -p 9001:9001 \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            minio/minio server /data --console-address ":9001"

      - name: Wait for MinIO
        run: |
          for i in $(seq 1 30); do
            if curl -fsS http://localhost:9000/minio/health/live > /dev/null 2>&1; then
              echo "MinIO is healthy"
              break
            fi
            sleep 1
          done

      - name: Create bucket
        run: |
          # Use MinIO client instead of AWS CLI for speed
          docker run --rm --network host \
            -e MC_HOST_minio=http://minioadmin:minioadmin@localhost:9000 \
            minio/mc mb minio/zombi-events

      - name: Run Zombi
        run: |
          docker run -d --name zombi \
            --network host \
            -e AWS_ACCESS_KEY_ID=minioadmin \
            -e AWS_SECRET_ACCESS_KEY=minioadmin \
            -e ZOMBI_S3_BUCKET=zombi-events \
            -e ZOMBI_S3_ENDPOINT=http://localhost:9000 \
            -e ZOMBI_S3_REGION=us-east-1 \
            -e ZOMBI_ICEBERG_ENABLED=true \
            -e ZOMBI_FLUSH_INTERVAL_SECS=1 \
            -e ZOMBI_FLUSH_BATCH_SIZE=1 \
            -e ZOMBI_FLUSH_MAX_SEGMENT=1 \
            zombi:pr-${{ github.event.pull_request.number }}

      - name: Wait for health
        run: |
          for i in $(seq 1 30); do
            if curl -fsS http://localhost:8080/health > /dev/null; then
              echo "Zombi is healthy"
              exit 0
            fi
            sleep 1
          done
          echo "Zombi did not become healthy in time"
          docker logs zombi
          exit 1

      - name: Test write endpoint
        run: |
          curl -fsS -X POST http://localhost:8080/tables/events \
            -H "Content-Type: application/json" \
            -d '{"payload":"hello from pr"}'

      - name: Test read endpoint
        run: |
          curl -fsS http://localhost:8080/tables/events | jq .

      - name: Test stats endpoint
        run: |
          curl -fsS http://localhost:8080/stats | jq .

      - name: Verify Iceberg data in MinIO
        run: |
          sleep 3
          echo "Listing all objects in bucket:"
          docker run --rm --network host \
            -e MC_HOST_minio=http://minioadmin:minioadmin@localhost:9000 \
            minio/mc ls minio/zombi-events --recursive
          echo "Checking for Iceberg structure:"
          docker run --rm --network host \
            -e MC_HOST_minio=http://minioadmin:minioadmin@localhost:9000 \
            minio/mc ls minio/zombi-events --recursive | grep -E "metadata/|data/" || echo "Warning: Iceberg structure not found yet"

      - name: Show Zombi logs
        if: always()
        run: docker logs zombi

  # Integration test with MinIO - runs on main only (uses published image)
  integration:
    name: Integration Test (Main)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: docker
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4

      - name: Start MinIO
        run: |
          docker run -d --name minio \
            -p 9000:9000 -p 9001:9001 \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            minio/minio server /data --console-address ":9001"

      - name: Create bucket
        run: |
          # Use MinIO client instead of AWS CLI for speed
          docker run --rm --network host \
            -e MC_HOST_minio=http://minioadmin:minioadmin@localhost:9000 \
            minio/mc mb minio/zombi-events

      - name: Log in to Container registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Run Zombi
        run: |
          docker run -d --name zombi \
            --add-host=host.docker.internal:host-gateway \
            -p 8080:8080 \
            -e AWS_ACCESS_KEY_ID=minioadmin \
            -e AWS_SECRET_ACCESS_KEY=minioadmin \
            -e ZOMBI_S3_BUCKET=zombi-events \
            -e ZOMBI_S3_ENDPOINT=http://host.docker.internal:9000 \
            -e ZOMBI_S3_REGION=us-east-1 \
            -e ZOMBI_ICEBERG_ENABLED=true \
            -e ZOMBI_FLUSH_INTERVAL_SECS=1 \
            -e ZOMBI_FLUSH_BATCH_SIZE=1 \
            -e ZOMBI_FLUSH_MAX_SEGMENT=1 \
            ghcr.io/${{ github.repository }}:latest

      - name: Wait for health
        run: |
          for i in $(seq 1 30); do
            if curl -fsS http://localhost:8080/health > /dev/null; then
              echo "Zombi is healthy"
              exit 0
            fi
            sleep 1
          done
          echo "Zombi did not become healthy in time"
          docker logs zombi
          exit 1

      - name: Test write endpoint
        run: |
          curl -fsS -X POST http://localhost:8080/tables/events \
            -H "Content-Type: application/json" \
            -d '{"payload":"hello from ci"}'

      - name: Test read endpoint
        run: |
          curl -fsS http://localhost:8080/tables/events | jq .

      - name: Test stats endpoint
        run: |
          curl -fsS http://localhost:8080/stats | jq .

      - name: Verify Iceberg data in MinIO
        run: |
          sleep 3
          echo "Listing all objects in bucket:"
          docker run --rm --network host \
            -e MC_HOST_minio=http://minioadmin:minioadmin@localhost:9000 \
            minio/mc ls minio/zombi-events --recursive
          echo "Checking for Iceberg structure (metadata/ and data/):"
          docker run --rm --network host \
            -e MC_HOST_minio=http://minioadmin:minioadmin@localhost:9000 \
            minio/mc ls minio/zombi-events --recursive | grep -E "metadata/|data/" || echo "Warning: Iceberg structure not found yet"

      - name: Show Zombi logs
        if: always()
        run: docker logs zombi

  # Deploy (optional) - only on main with configured secrets
  deploy:
    name: Deploy
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: integration
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to Server
        uses: appleboy/ssh-action@v1.0.3
        env:
          SSH_HOST: ${{ secrets.SSH_HOST }}
          SSH_USER: ${{ secrets.SSH_USER }}
          SSH_KEY: ${{ secrets.SSH_KEY }}
        if: env.SSH_HOST != '' && env.SSH_USER != '' && env.SSH_KEY != ''
        with:
          host: ${{ secrets.SSH_HOST }}
          username: ${{ secrets.SSH_USER }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            # Pull latest image
            docker pull ghcr.io/${{ github.repository }}:latest

            # Stop existing container
            docker stop zombi || true
            docker rm zombi || true

            # Start new container
            docker run -d \
              --name zombi \
              --restart always \
              -p 8080:8080 \
              -v zombi-data:/var/lib/zombi \
              -e ZOMBI_HOST=0.0.0.0 \
              -e ZOMBI_PORT=8080 \
              ghcr.io/${{ github.repository }}:latest
